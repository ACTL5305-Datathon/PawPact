---
title: "Datathon Internal EDA"
author: "Helitha Dharmadasa - z5451805"
date: "2024-10-01"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library("tidyverse")
library("AER")
library("stringr")
```

## Read Data

```{r}
claims_data <- read_csv('../data/internal/UNSW_claims_data.csv', col_names = TRUE)

earned_data <- read_csv('../data/internal/UNSW_earned_data_adjusted_Sep27.csv', col_names = TRUE)
```

```{r}
summary(earned_data)
```


```{r}
#Some cleaning
#  Remove negative tenures (makes no sense)
#  Remove 0 total claim amounts
claims_data <- claims_data %>% filter(tenure >= 0) %>% filter(total_claim_amount > 0)

claims_data <- claims_data %>%
  filter(!str_detect(claim_status, "not_paid"))


earned_data <- earned_data %>% filter(tenure >= 0)
```


```{r}
# Keep only the lastest entries for each exposure
unique_exposures <- earned_data %>%
  arrange(desc(UW_Date)) %>%  
  group_by(exposure_id) %>%      
  slice(1) %>%                 
  ungroup() 

earned_data %>% distinct(exposure_id) %>% count()
```


```{r}
# Get a df of unique breeds
unique_breeds <- earned_data %>%
  separate_rows(nb_breed_name_unique_concat, sep = ",") %>%
  mutate(nb_breed_name_unique_concat = str_trim(nb_breed_name_unique_concat)) %>%
  mutate(nb_breed_name_unique_concat = gsub("\\s*cross\\s*", "", nb_breed_name_unique_concat)) %>%
  group_by(nb_breed_name_unique_concat) %>%
  summarise(breed_count = n())
  #distinct(nb_breed_name_unique_concat) 
```


# Claims

```{r}
unique_conditions <- claims_data %>% 
  group_by(condition_category) %>% 
  summarise(claim_count = n())
```


```{r}
unique_claim_types <- claims_data %>% 
  group_by(claim_status) %>% 
  summarise(claim_count = n())
```


```{r}
# Using tenure was equivalent and simpler
#claims_data <- claims_data %>%
#  mutate(claim_month = floor_date(claim_start_date, "month"))

claims_count <- claims_data %>% 
  group_by(exposure_id, tenure) %>% 
  summarise(claim_count = n(), .groups = 'drop')
```

```{r}
frequency_df <- full_join(earned_data, claims_count, by = c("exposure_id", "tenure"))

frequency_df <- frequency_df %>%
  mutate(claim_count = replace_na(claim_count, 0),
         claim_count_indicator = ifelse(claim_count > 0, 1, 0))
```

```{r}
hist(frequency_df$claim_count_indicator) 
hist(frequency_df$claim_count) 
```

```{r}
#Probably select(c("exposure_id", "tenure", "total_claim_amount"))
severity_df <- left_join(claims_data, earned_data, by = c("exposure_id", "tenure"))

#total claim amount = claim Paid / contribution + excess / gst
#167.07/0.9+100/1.1
#claim paid = (total claim amount - excess / gst ) * contribution

severity_df <- severity_df %>%
  group_by(condition_category, exposure_id) %>%
  mutate(excess_flag = ifelse(row_number() == 1, 1, 0)) %>%
  ungroup()

severity_df <- severity_df %>% 
  mutate(claim_due_excess = (total_claim_amount - (nb_excess)/1.1)*(nb_contribution/100),
         claim_due_no_excess = total_claim_amount*(nb_contribution/100)) %>%
  arrange(claim_start_date, exposure_id, claim_id) 
```

```{r}
unique_breed_conditions <- severity_df %>%
  separate_rows(nb_breed_name_unique_concat, sep = ",") %>%
  mutate(nb_breed_name_unique_concat = str_trim(nb_breed_name_unique_concat)) %>%
  group_by(nb_breed_name_unique_concat, condition_category) %>%
  summarise(breed_count = n(),
            average_claim = mean(claim_paid),
            sd_claim = sd(claim_paid))
```


```{r}
# Duplicate Claim IDs - This still needs to be dealt with
dupe_claims <- severity_df %>%
  group_by(claim_id) %>%
  filter(n() > 1) %>%
  ungroup() %>%
  arrange(claim_start_date, exposure_id, claim_id) 
```

```{r}
severity_df %>% 
  select(claim_status) %>%
  distinct()

# Exclude these as well
unpaid_claims <- severity_df %>%
  filter(str_detect(claim_status, "not_paid"))


```

```{r}
earned_data <- earned_data %>%
  mutate(pet_de_sexed_age = case_when(
    str_detect(pet_de_sexed_age, "0-3") ~ "0-3 months",
    str_detect(pet_de_sexed_age, "4-6") ~ "4-6 months",
    str_detect(pet_de_sexed_age, "7-12") ~ "7-12 months",
    str_detect(pet_de_sexed_age, "1-2") ~ "1-2 years",
    str_detect(pet_de_sexed_age, "2\\+") ~ "2+ years"
  )) %>%
  replace_na(list(pet_de_sexed_age = "FALSE"))
```

```{r}
earned_data %>% 
  select(pet_de_sexed_age) %>%
  distinct()
```

```{r}
earned_data <- earned_data %>%
  replace_na(list(nb_breed_trait = "unknown"))
```


```{r}
earned_data %>% 
  select(nb_breed_trait) %>%
  distinct()
```
```{r}
earned_data %>% 
  select(nb_average_breed_size) %>%
  distinct()
```


```{r}
tweedie_df <- claims_data %>% 
  select(c("exposure_id", "tenure", "total_claim_amount")) %>%
  full_join(earned_data, by = c("exposure_id", "tenure")) %>%
  mutate(total_claim_amount = replace_na(total_claim_amount, 0))
```


```{r}
earned_data %>%
  select(pet_de_sexed_age) %>%
  distinct()
```
```{r}
earned_data <- earned_data %>%
  replace_na(list(nb_breed_trait = "unknown"))

earned_data <- earned_data %>%
  replace_na(list(pet_is_switcher = FALSE))
```

```{r}
earned_data %>%
  select(person_dob) %>%
  distinct()
```

```{r}
na_df <- earned_data %>%
  filter(if_any(everything(), is.na))

earned_data <- earned_data %>%
  filter(!is.na(person_dob))
```


```{r}
earned_data %>%
  summarise(across(everything(), ~ anyNA(.))) %>%
  pivot_longer(everything(), names_to = "column", values_to = "has_na") %>%
  filter(has_na) %>%
  pull(column)
```

```{r}

```




```{r}
#ToDo:
#-Clean up duplicate claim_ids
#-Create historical claims features -- past claims history allowed/useful for preds
#-save frequency, severity, tweedie df to csv files
```















